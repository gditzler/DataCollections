#!/usr/bin/env python 
import json 
import argparse 
import pandas as pd
import numpy as np
import csv 
import itertools 

__authors__ = "Gregory Ditzler"
__copyright__ = "Copyright 2014, Gregory Ditzler"
__license__ = "GPL"
__maintainer__ = "Gregory Ditzler"
__email__ = "gregory.ditzler@gmail.com"

def load_biom(biom_fp):
  """
  Load a biom file and return the data matrix, sampled IDs, OTU names, and 
  the OTU ID. 
  .biom_fp 
  .data
  .sample_ids
  .otu_names
  .otu_ids
  """
  biom_dat = json.loads(open(biom_fp, "rb").read())
  otu_names = [json.dumps(df["metadata"]["taxonomy"]) for df in biom_dat["rows"]]
  otu_ids = [df["id"] for df in biom_dat["rows"]]
  sample_ids = [df["id"] for df in biom_dat["columns"]]
  matrix = np.zeros(biom_dat["shape"])
  for i, j, val in biom_dat["data"]:
    matrix[i, j] = val
  return matrix, sample_ids, otu_names, otu_ids

def load_map(map_fp):
  """
  Read in the tab-delimited map file
  """
  meta_data = {}
  with open(map_fp, "rb") as fh:
    first = fh.readline()
    if first[0] != "#":
      exit('Error: expected tab delimted field labels starting with # in map file on line 1')

    first = first.strip('#')
    reader = csv.DictReader(itertools.chain([first], fh), delimiter="\t")

    try:
      reader_arr = [row for row in reader]
      headers = reader.fieldnames
    except csv.Error as e:
      exit("Error: map file contains error at line %d: %s" % (reader.line_num, e))

    if "SampleID" not in headers:
      exit("Error: no SampleID column in map file")

    labels = filter(lambda label: label != "SampleID", headers)

    for row in reader_arr:
      meta_data[row["SampleID"]] = {}
      for label in labels:
        meta_data[row["SampleID"]][label] = row[label]

    return meta_data
  #return pd.read_csv(map_fp, sep="\t")

def build_opt_parse():
  """
  Build the option parser
  .parser
  """
  parser = argparse.ArgumentParser(
      description = ("Convert a Biom and mao file pair to a set of CSV files "
        "containing the dense OTU table with a corresponding label file. The "
        "rows are ordered to keep the new data and label file in check with "
        "each other.\n")
      )
  parser.add_argument(
      "-i",
      "--input",
      help="Path to the Biom file."
      )
  parser.add_argument(
      "-m",
      "--map",
      help="Path to the map file."
      )
  parser.add_argument(
      "-c",
      "--col",
      help="Column of the map file that contains the labels."
      )
  parser.add_argument(
      "-d",
      "--matrix",
      help="Path to the output data matrix."
      )
  parser.add_argument(
      "-l",
      "--label",
      help="Path to the class label file."
      )
  parser.add_argument(
      "-f",
      "--features",
      help="Path to the class label file."
      )
  return parser

def main():
  """
  do everything here 
  """
  parser = build_opt_parse()
  args = parser.parse_args()
  data, sample_ids, otu_names, otu_ids = load_biom(args.input)
  #metadata = { x[1]:x[2] for x in load_map(args.map)[["#SampleID",args.col]].itertuples()}
  metadata = load_map(args.map)
  labels = [metadata[key][args.col] for key in sample_ids]

  f = open(args.label, "w")
  for l in labels[:-1]:
    f.write(l+"\n")
  f.write(labels[-1])  # avoid the extra return char
  f.close()

  f = open(args.features, "w")
  for name, ids in map(None, otu_names[:-1], otu_ids[:-1]):
    f.write(name+" ("+str(ids)+")\n")
  f.write(otu_names[-1]+"("+str(ids)+")")  # avoid the extra return char
  f.close()

  np.savetxt(args.matrix, data.transpose(), delimiter=",", fmt="%s")
  
  return None 

if __name__ == "__main__":
  main()

